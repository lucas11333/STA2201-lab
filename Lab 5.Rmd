---
title: 'Lab 5 '
author: 'SHAOHAN CHANG'
date: 02-12-2023
date-format: DD/MM/YYYY
output: pdf_document
format: pdf
---


# Introduction

Today we will be starting off using Stan, looking at the kid's test score data set (available in resources for the [Gelman Hill textbook](https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html)). 

```{r message=FALSE}
library(tidyverse)
library(rstan)
library(tidybayes)
library(here)
```


The data look like this:

```{r message=FALSE}
kidiq <- readRDS("C:/Users/admin/Desktop/Lab 5/kidiq.RDS")
kidiq
```
As well as the kid's test scores, we have a binary variable indicating whether or not the mother completed high school, the mother's IQ and age. 


# Descriptives

## Question 1

Use plots or tables to show three interesting observations about the data. Remember:

- Explain what your graph/ tables show
- Choose a graph type that's appropriate to the data type


Conclusion by choosing the graph,for the first figure, a scatter plot would be an appropriate graph type to show the relationship between the mother's IQ and the child's score. Each data point represents a mother-child pair, and the x-axis would represent the mother's IQ and the y-axis would represent the child's score. This would allow us to visually observe the trend of increasing child scores with increasing mother's IQ.Compared to the other two figures, it is difficult to find any clear results.


```{r message=FALSE}
library(ggplot2)
library(dplyr)

kidiq %>%ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() + 
geom_smooth(method = "lm")+ theme_bw()
```


From the above figure, which shows the scores of children tend to increase with their mother's IQ.


```{r message=FALSE}
kidiq %>% group_by(mom_hs)%>%
  ggplot() +
geom_histogram(aes(x = kid_score, colour = mom_hs)) + 
theme_bw()+facet_wrap(mom_hs ~ . )
```


The second figure shows the distribution of children's scores is different based on their mother's education level, with those whose mothers did not complete high school having a flatter distribution with less high scores. This is expected as a lack of high school education is often a proxy for lower income and resources. On the other hand, children of mothers who completed high school have higher kid_scores.

```{r message=FALSE}
kidiq %>%ggplot(aes(x = mom_age, y = kid_score)) +geom_point() +
geom_smooth(method = "lm") +theme_bw()
```

The third figure shows that there is minimal correlation between the age of the mother and the score of their child. This suggests that the mother's age may not be a contributing factor to the child's score. The lack of relationship between these two variables is not surprising, but it is also not particularly noteworthy.
In summary, the relationship between the mother's age and the child's score is weak and does not appear to be a significant factor. This result is not surprising and does not offer any exceptional insights.


# Estimating mean, no covariates

In class we were trying to estimate the mean and standard deviation of the kid's test scores. The `kids2.stan` file contains a Stan model to do this. If you look at it, you will notice the first `data` chunk lists some inputs that we have to define: the outcome variable `y`, number of observations `N`, and the mean and standard deviation of the prior on `mu`. Let's define all these values in a `data` list.


```{r message=FALSE ,warning=FALSE}
y <- kidiq$kid_score
mu0 <- 80
sigma0 <- 10

# named list to input for stan function
data <- list(y = y, 
             N = length(y), 
             mu0 = mu0,
             sigma0 = sigma0)
```



Now we can run the model:

```{r message=FALSE ,warning=FALSE}
fit <- stan(file ="C:/Users/admin/Desktop/Lab 5/kids2.stan",
            data = data,
            chains = 3,
            iter = 500)
```

Look at the summary

```{r message=FALSE ,warning=FALSE}
fit
```

Traceplot

```{r message=FALSE ,warning=FALSE}
traceplot(fit)
```

All looks fine. 

```{r message=FALSE ,warning=FALSE}
pairs(fit, pars = c("mu", "sigma"))
```

```{r message=FALSE ,warning=FALSE}
stan_dens(fit, separate_chains = TRUE)
```


## Understanding output

What does the model actually give us? A number of samples from the posteriors. To see this, we can use `extract` to get the samples. 

```{r message=FALSE ,warning=FALSE}
post_samples <- extract(fit)
head(post_samples[["mu"]])
```


This is a list, and in this case, each element of the list has 4000 samples. E.g. quickly plot a histogram of mu

```{r message=FALSE ,warning=FALSE}
hist(post_samples[["mu"]])
median(post_samples[["mu"]])
# 95% bayesian credible interval
quantile(post_samples[["mu"]], 0.025)
quantile(post_samples[["mu"]], 0.975)
```



## Plot estimates

There are a bunch of packages, built-in functions that let you plot the estimates from the model, and I encourage you to explore these options (particularly in `bayesplot`, which we will most likely be using later on). I like using the `tidybayes` package, which allows us to easily get the posterior samples in a tidy format (e.g. using gather draws to get in long format). Once we have that, it's easy to just pipe and do ggplots as usual. 


Get the posterior samples for mu and sigma in long format:

```{r message=FALSE ,warning=FALSE}
draw_samples <- fit  %>% 
  gather_draws(mu, sigma) # gather = long format

head(draw_samples)

# wide format
fit  %>%  spread_draws(mu, sigma)

# quickly calculate the quantiles using 

draw_samples %>% median_qi(.width = 0.8)
```

Let's plot the density of the posterior samples for mu and add in the prior distribution

```{r message=FALSE ,warning=FALSE}
draw_samples %>% 
  filter(.variable == "mu") %>% 
  ggplot(aes(.value, color = "posterior")) + geom_density() + 
  xlim(c(70, 110)) + 
  stat_function(fun = dnorm, 
        args = list(mean = mu0, 
                    sd = sigma0), 
        aes(colour = 'prior')) +
  scale_color_manual(name = "", values = c("prior" = 1, "posterior" = 2)) + 
  xlab("score")+ggtitle("Prior and posterior for mean test scores") 
  
```

## Question 2

Change the prior to be much more informative (by changing the standard deviation to be 0.1). Rerun the model. Do the estimates change? Plot the prior and posterior densities. 

```{r message=FALSE ,warning=FALSE}
sigma0 = 0.1 # Value setting 
data2 <- list(y = y,N = length(y),mu0 = mu0,sigma0 = sigma0)
fit2 <- stan(file ="C:/Users/admin/Desktop/Lab 5/kids2.stan",data = data2) # The file of kids2.stan
             
draw_samples2<- fit2 %>% gather_draws(mu, sigma)

draw_samples2%>%filter(.variable == "mu") %>%
  ggplot(aes(.value, color = "posterior")) + 
  geom_density() +xlim(c(60, 110))+xlab("score") +
  stat_function(fun = dnorm,args = list(mean = mu0,sd = sigma0),aes(colour = 'prior'), size = 1) +
  scale_color_manual(name = "", values = c("prior" = 1, "posterior" = 2)) +
  ggtitle("The Mean Test Scores for Prior and Posterior")  


             
```




# Adding covariates

Now let's see how kid's test scores are related to mother's education. We want to run the simple linear regression

$$
Score = \alpha + \beta X
$$
where $X = 1$ if the mother finished high school and zero otherwise. 

`kid3.stan` has the stan model to do this. Notice now we have some inputs related to the design matrix $X$ and the number of covariates (in this case, it's just 1).

Let's get the data we need and run the model. 




```{r message=FALSE ,warning=FALSE}
X <- as.matrix(kidiq$mom_hs, ncol = 1) # force this to be a matrix
K <- 1
data <- list(y = y, N = length(y), 
             X =X, K = K)
fit2 <- stan(file = here("C:/Users/admin/Desktop/Lab 5/kids3.stan"), # fit2 represent the kids3 file
            data = data, 
            iter = 1000)
```




## Question 3

a) Confirm that the estimates of the intercept and slope are comparable to results from `lm()` 


```{r message=FALSE ,warning=FALSE}
lm_model<- lm(kid_score ~ mom_hs,data=kidiq)
summary(lm_model)
fit2
```

The results of two models, one fitted by Stan and one fitted by a linear model, were compared for the estimates of the intercept and slope. The Stan model estimated the intercept to be 78 and the slope to be 11, while the linear model estimated the intercept to be 77.5 and the slope to be 11. The results of these two models were found to be similar.


b) Do a `pairs` plot to investigate the joint sample distributions of the slope and intercept. Comment briefly on what you see. Is this potentially a problem?


```{r message=FALSE ,warning=FALSE}
pairs(fit2,pars=c("alpha","beta"),las = 1)
```

The joint distribution of the slope and intercept estimations was analyzed, and it was found that there may be other factors affecting the child's score besides the mother's education level. This is because the distribution of the intercept estimates showed a relatively large degree of variability.

## Plotting results

It might be nice to plot the posterior samples of the estimates for the non-high-school and high-school mothered kids. Here's some code that does this: notice the `beta[condition]` syntax. Also notice I'm using `spread_draws`, because it's easier to calculate the estimated effects in wide format



```{r message=FALSE ,warning=FALSE}
fit2 |>
  spread_draws(alpha, beta[k], sigma) |> 
     mutate(nhs = alpha, # no high school is just the intercept
          hs = alpha + beta) |> 
  select(nhs, hs) |> 
  pivot_longer(nhs:hs, names_to = "education", 
               values_to = "estimated_score") |> 
  ggplot(aes(y = education, x = estimated_score)) +
  stat_halfeye() + 
  theme_bw() + 
  ggtitle("Posterior estimates of scores by education level of mother")
```




## Question 4

Add in mother's IQ as a covariate and rerun the model. Please  mean center the covariate before putting it into the model. Interpret the coefficient on the (centered) mum's IQ. 




```{r message=FALSE ,warning=FALSE}
kidiq <- kidiq %>% 
mutate(centered_iq = scale(mom_iq, scale = FALSE))
X <- cbind(as.matrix(kidiq$mom_hs, ncol = 1), as.matrix(kidiq$centered_iq, ncol = 1))

data4 <- list(y = y, N = length(y),X = X, K = 2)
fit4 <- stan(file="C:/Users/admin/Desktop/Lab 5/kids3.stan",data = data4,iter = 500)

fit4
```


Interpretation:
For every one point increase above average in the mother's IQ, the estimated score of the child is expected to rise by approximately 0.57, according to the estimate of the coefficient.

## Question 5 

Confirm the results from Stan agree with `lm()`


```{r message=FALSE ,warning=FALSE}
lm_model2<- lm(kid_score ~ mom_hs + mom_iq,data = kidiq)
summary(lm_model2)
```

The coefficient estimate for the mother's IQ in the linear model (LM) was approximately 0.56, which is consistent with the estimate from the Stan model. The estimate for the mother's education level (mum_hs) in LM was about 5.95, which is similar to the estimate from Stan. However, the estimate of the intercept in LM was 25.7, whereas the estimate from Stan was 82.39.

## Question 6

Plot the posterior estimates of scores by education of mother for mothers who have an IQ of 110. 



```{r message=FALSE ,warning=FALSE}
mean(kidiq$mom_iq)

fit4 |>  # assign the value to fit4 , which reprsent the file of kid3.
spread_draws(alpha, beta[condition], sigma) |>
pivot_wider(names_from = condition, names_prefix = "beta", values_from = beta) |>
transmute(no_high = alpha + beta2 * 10, high = alpha + beta1 + beta2 * 10) |>
pivot_longer(cols = c(no_high, high), names_to = "education", values_to = "estimated_score") |>
ggplot(aes(y = education, x = estimated_score)) + stat_halfeye() +
ggtitle("Posterior estimates of kid_score for mothers with IQ 110")
```



## Question 7

Generate and plot (as a histogram) samples from the posterior predictive distribution for a new kid with a mother who graduated high school and has an IQ of 95. 


```{r message=FALSE ,warning=FALSE}


fit4 %>%spread_draws(alpha, beta[condition], sigma) %>%
pivot_wider(names_from = condition, names_prefix = "beta", values_from = beta) %>%
mutate(hs = alpha + beta1 + beta2 *(-5)) %>%
pivot_longer(hs, names_to = "education", values_to = "estimated_score") %>%
ggplot(aes( x = estimated_score)) +geom_histogram() +
ggtitle("Posterior estimates of key_score with a mother who graduated high school and has an IQ of 95")


```

